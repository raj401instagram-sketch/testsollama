name: Ollama Server Ultra-Robust Edition

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model to load (e.g., qwen2.5:7b, llama3.1:8b)'
        required: true
        default: 'qwen2.5:0.5b'
        type: choice
        options:
          - 'qwen2.5:0.5b'
          - 'qwen2.5:1.5b'
          - 'qwen2.5:3b'
          - 'qwen2.5:7b'
          - 'llama3.1:8b'
          - 'mistral:7b'
          - 'phi3:mini'
          - 'custom'
      custom_model:
        description: 'Custom model name (if "custom" selected above)'
        required: false
        type: string
      test_prompt:
        description: 'Test prompt after model loads'
        required: false
        default: 'Hello! Please respond with your model name and capabilities.'
        type: string
      keep_alive_minutes:
        description: 'How long to keep server running (5-30 minutes)'
        required: false
        default: '20'
        type: choice
        options:
          - '5'
          - '10'
          - '15'
          - '20'
          - '25'
          - '30'
      tunnel_provider:
        description: 'Tunnel provider to use'
        required: false
        default: 'cloudflare'
        type: choice
        options:
          - 'cloudflare'
          - 'ngrok'
          - 'both'
      enable_monitoring:
        description: 'Enable enhanced monitoring'
        required: false
        default: true
        type: boolean
      retry_on_failure:
        description: 'Auto-retry on failures'
        required: false
        default: true
        type: boolean

env:
  OLLAMA_HOST: 0.0.0.0:11543
  OLLAMA_MODELS: /home/runner/.ollama/models
  OLLAMA_KEEP_ALIVE: 30m
  OLLAMA_ORIGINS: "*"
  WEBHOOK_URL: ${{ secrets.WEBHOOK_URL || 'https://n8n-latest-l4cl.onrender.com/webhook/034c8802-f6d2-4819-b1fc-04b90835c013' }}
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN || '' }}
  TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID || '' }}
  NGROK_AUTH_TOKEN: ${{ secrets.NGROK_AUTH_TOKEN || '' }}
  MAX_RETRIES: 3
  HEALTH_CHECK_INTERVAL: 30
  MEMORY_THRESHOLD: 90

jobs:
  # Pre-flight checks job
  preflight-checks:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_proceed: ${{ steps.checks.outputs.proceed }}
      runner_id: ${{ steps.checks.outputs.runner_id }}
      cache_key: ${{ steps.checks.outputs.cache_key }}
    
    steps:
    - name: ðŸ” Pre-flight System Checks
      id: checks
      run: |
        echo "::group::System Pre-flight Checks"
        
        # Generate unique runner ID
        RUNNER_ID="runner-$(date +%s)-${GITHUB_RUN_ID}"
        echo "runner_id=$RUNNER_ID" >> $GITHUB_OUTPUT
        
        # Check system resources
        AVAILABLE_MEMORY=$(free -m | awk 'NR==2{print $7}')
        AVAILABLE_DISK=$(df -BG / | awk 'NR==2{print $4}' | sed 's/G//')
        
        echo "ðŸ“Š System Resources:"
        echo "  Memory Available: ${AVAILABLE_MEMORY}MB"
        echo "  Disk Available: ${AVAILABLE_DISK}GB"
        
        # Validate inputs
        MODEL="${{ github.event.inputs.model }}"
        if [[ "$MODEL" == "custom" ]]; then
          MODEL="${{ github.event.inputs.custom_model }}"
          if [[ -z "$MODEL" ]]; then
            echo "âŒ Custom model name not provided"
            echo "proceed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
        fi
        
        # Generate cache key with fallback
        CACHE_KEY="ollama-${RUNNER_OS}-${MODEL//[:\/]/-}-v3"
        echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT
        
        # Check if we should proceed
        if [[ $AVAILABLE_MEMORY -lt 1000 ]]; then
          echo "âš ï¸ Low memory warning: ${AVAILABLE_MEMORY}MB available"
        fi
        
        if [[ $AVAILABLE_DISK -lt 5 ]]; then
          echo "âŒ Insufficient disk space: ${AVAILABLE_DISK}GB available"
          echo "proceed=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        echo "âœ… Pre-flight checks passed"
        echo "proceed=true" >> $GITHUB_OUTPUT
        echo "::endgroup::"
    
    - name: ðŸ“¡ Send Pre-flight Notification
      if: env.WEBHOOK_URL != ''
      continue-on-error: true
      run: |
        curl -X POST "${{ env.WEBHOOK_URL }}" \
          -H "Content-Type: application/json" \
          -d '{
            "event": "workflow_starting",
            "run_id": "${{ github.run_id }}",
            "runner_id": "${{ steps.checks.outputs.runner_id }}",
            "model": "${{ github.event.inputs.model }}",
            "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
          }' || echo "Webhook notification failed (non-critical)"

  # Main Ollama server job
  ollama-server:
    needs: preflight-checks
    if: needs.preflight-checks.outputs.should_proceed == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: ðŸš€ Checkout Repository
      uses: actions/checkout@v4
      with:
        clean: true
        
    - name: ðŸ› ï¸ Setup Environment
      run: |
        echo "::group::Environment Setup"
        
        # Create necessary directories with proper permissions
        mkdir -p logs/{server,tunnel,monitoring,health}
        mkdir -p /home/runner/.ollama/{models,manifests,blobs}
        chmod -R 755 logs /home/runner/.ollama
        
        # Initialize log files
        touch logs/timeline.log logs/error.log logs/recovery.log
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Environment setup started" >> logs/timeline.log
        
        # Set up error trap
        trap 'echo "$(date): Error occurred on line $LINENO" >> logs/error.log' ERR
        
        # Create health check script
        cat > health_check.sh << 'EOF'
        #!/bin/bash
        OLLAMA_URL="http://0.0.0.0:11543"
        MAX_ATTEMPTS=3
        ATTEMPT=1
        
        while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
          if curl -sf "$OLLAMA_URL/api/tags" > /dev/null 2>&1; then
            echo "âœ… Health check passed"
            exit 0
          fi
          echo "âš ï¸ Health check attempt $ATTEMPT/$MAX_ATTEMPTS failed"
          ATTEMPT=$((ATTEMPT + 1))
          sleep 2
        done
        
        echo "âŒ Health check failed after $MAX_ATTEMPTS attempts"
        exit 1
        EOF
        
        chmod +x health_check.sh
        
        # Create recovery script
        cat > recovery.sh << 'EOF'
        #!/bin/bash
        echo "ðŸ”§ Attempting recovery..." >> logs/recovery.log
        
        # Kill hung processes
        pkill -9 -f ollama 2>/dev/null || true
        pkill -9 -f cloudflared 2>/dev/null || true
        pkill -9 -f ngrok 2>/dev/null || true
        
        # Clean up locks and temp files
        rm -f /tmp/ollama.lock /tmp/*.sock 2>/dev/null || true
        
        # Wait for cleanup
        sleep 3
        
        # Restart Ollama
        nohup ollama serve > logs/server/ollama-recovery.log 2>&1 &
        echo $! > logs/ollama.pid
        
        # Wait for startup
        for i in {1..30}; do
          if curl -sf http://0.0.0.0:11543/api/tags > /dev/null 2>&1; then
            echo "âœ… Recovery successful" >> logs/recovery.log
            exit 0
          fi
          sleep 2
        done
        
        echo "âŒ Recovery failed" >> logs/recovery.log
        exit 1
        EOF
        
        chmod +x recovery.sh
        
        echo "::endgroup::"
        
    - name: ðŸ“Š System Information
      run: |
        echo "::group::System Information"
        cat > logs/system_info.json << EOF
        {
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "runner_id": "${{ needs.preflight-checks.outputs.runner_id }}",
          "os": "$(uname -a)",
          "memory_total": "$(free -h | awk 'NR==2{print $2}')",
          "memory_available": "$(free -h | awk 'NR==2{print $7}')",
          "cpu_count": "$(nproc)",
          "cpu_model": "$(lscpu | grep 'Model name' | cut -d: -f2 | xargs)",
          "disk_available": "$(df -h / | awk 'NR==2{print $4}')",
          "kernel": "$(uname -r)",
          "architecture": "$(uname -m)"
        }
        EOF
        
        cat logs/system_info.json | jq '.'
        echo "::endgroup::"
        
    - name: ðŸ“¦ Advanced Cache Management
      id: cache
      run: |
        echo "::group::Cache Management"
        
        # Try multiple cache strategies
        CACHE_KEY="${{ needs.preflight-checks.outputs.cache_key }}"
        
        echo "ðŸ“¦ Cache Configuration:"
        echo "  Primary Key: $CACHE_KEY"
        echo "  Restore Keys: ollama-${RUNNER_OS}-, ollama-"
        
        # Check if cache directory exists and is valid
        if [[ -d /home/runner/.ollama/models ]]; then
          MODEL_COUNT=$(find /home/runner/.ollama/models -type f 2>/dev/null | wc -l)
          echo "  Existing models found: $MODEL_COUNT files"
          
          # Validate cache integrity
          if [[ $MODEL_COUNT -gt 0 ]]; then
            echo "  Cache appears valid"
            echo "cache_valid=true" >> $GITHUB_OUTPUT
          else
            echo "  Cache empty or corrupted"
            echo "cache_valid=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "  No cache directory found"
          echo "cache_valid=false" >> $GITHUB_OUTPUT
        fi
        
        echo "::endgroup::"
        
    - name: ðŸ“¦ Restore Ollama Cache
      uses: actions/cache@v4
      id: cache-ollama
      with:
        path: |
          /home/runner/.ollama
          /usr/local/bin/ollama
          /usr/local/bin/cloudflared
        key: ${{ needs.preflight-checks.outputs.cache_key }}
        restore-keys: |
          ollama-${{ runner.os }}-${{ github.event.inputs.model }}-
          ollama-${{ runner.os }}-
          ollama-
          
    - name: â¬‡ï¸ Install Ollama with Fallback
      run: |
        echo "::group::Ollama Installation"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Installing Ollama" >> logs/timeline.log
        
        install_ollama() {
          local method=$1
          echo "ðŸ”§ Attempting installation via $method..."
          
          case $method in
            "cached")
              if [[ -f /usr/local/bin/ollama ]] && /usr/local/bin/ollama --version 2>/dev/null; then
                echo "âœ… Using cached Ollama"
                return 0
              fi
              ;;
            "official")
              if curl -fsSL https://ollama.com/install.sh | sh; then
                echo "âœ… Installed via official script"
                return 0
              fi
              ;;
            "direct")
              if wget -q https://github.com/ollama/ollama/releases/latest/download/ollama-linux-amd64 -O /tmp/ollama && \
                 sudo mv /tmp/ollama /usr/local/bin/ollama && \
                 sudo chmod +x /usr/local/bin/ollama; then
                echo "âœ… Installed via direct download"
                return 0
              fi
              ;;
            "package")
              if sudo apt-get update -qq && sudo apt-get install -y ollama; then
                echo "âœ… Installed via package manager"
                return 0
              fi
              ;;
          esac
          
          return 1
        }
        
        # Try installation methods in order
        for method in cached official direct package; do
          if install_ollama $method; then
            break
          fi
          echo "âš ï¸ Method $method failed, trying next..."
        done
        
        # Verify installation
        if ! command -v ollama &> /dev/null; then
          echo "âŒ Failed to install Ollama"
          exit 1
        fi
        
        ollama --version
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Ollama installation completed" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸ”§ Install Tunnel Providers
      run: |
        echo "::group::Tunnel Installation"
        
        # Install Cloudflared
        install_cloudflared() {
          if [[ -f /usr/local/bin/cloudflared ]] && /usr/local/bin/cloudflared --version 2>/dev/null; then
            echo "âœ… Cloudflared already installed"
            return 0
          fi
          
          echo "ðŸ“¥ Installing Cloudflared..."
          for attempt in {1..3}; do
            if wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && \
               sudo dpkg -i cloudflared-linux-amd64.deb 2>/dev/null || sudo apt-get install -f -y; then
              echo "âœ… Cloudflared installed"
              return 0
            fi
            echo "âš ï¸ Attempt $attempt failed"
            sleep 2
          done
          
          return 1
        }
        
        # Install ngrok if token provided
        install_ngrok() {
          if [[ -z "${{ env.NGROK_AUTH_TOKEN }}" ]]; then
            echo "â„¹ï¸ Ngrok token not provided, skipping"
            return 0
          fi
          
          echo "ðŸ“¥ Installing ngrok..."
          if curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && \
             echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | sudo tee /etc/apt/sources.list.d/ngrok.list && \
             sudo apt-get update -qq && sudo apt-get install -y ngrok; then
            ngrok config add-authtoken ${{ env.NGROK_AUTH_TOKEN }}
            echo "âœ… Ngrok installed and configured"
            return 0
          fi
          
          return 1
        }
        
        TUNNEL_PROVIDER="${{ github.event.inputs.tunnel_provider }}"
        
        if [[ "$TUNNEL_PROVIDER" == "cloudflare" ]] || [[ "$TUNNEL_PROVIDER" == "both" ]]; then
          install_cloudflared || echo "âš ï¸ Cloudflared installation failed"
        fi
        
        if [[ "$TUNNEL_PROVIDER" == "ngrok" ]] || [[ "$TUNNEL_PROVIDER" == "both" ]]; then
          install_ngrok || echo "âš ï¸ Ngrok installation failed"
        fi
        
        echo "::endgroup::"
        
    - name: ðŸ§¹ Cleanup Environment
      run: |
        echo "::group::Environment Cleanup"
        
        # Function to safely kill processes
        safe_kill() {
          local process=$1
          local pids=$(pgrep -f "$process" 2>/dev/null || true)
          
          if [[ ! -z "$pids" ]]; then
            echo "ðŸ”ª Terminating $process processes: $pids"
            for pid in $pids; do
              kill -TERM $pid 2>/dev/null || true
            done
            sleep 2
            
            # Force kill if still running
            for pid in $pids; do
              if kill -0 $pid 2>/dev/null; then
                echo "âš ï¸ Force killing $pid"
                kill -9 $pid 2>/dev/null || true
              fi
            done
          fi
        }
        
        # Clean up processes
        safe_kill "ollama"
        safe_kill "cloudflared"
        safe_kill "ngrok"
        
        # Clean up temp files and locks
        rm -f /tmp/ollama.* /tmp/*.sock 2>/dev/null || true
        
        # Clean up ports
        for port in 11543 11434 4040; do
          if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1; then
            echo "ðŸ”§ Freeing port $port"
            fuser -k $port/tcp 2>/dev/null || true
          fi
        done
        
        echo "âœ… Environment cleaned"
        echo "::endgroup::"
        
    - name: ðŸš€ Start Ollama Server with Health Monitoring
      id: start-ollama
      run: |
        echo "::group::Starting Ollama Server"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Starting Ollama server" >> logs/timeline.log
        
        # Export environment variables
        export OLLAMA_HOST=0.0.0.0:11543
        export OLLAMA_MODELS=/home/runner/.ollama/models
        export OLLAMA_ORIGINS="*"
        export OLLAMA_KEEP_ALIVE=30m
        export OLLAMA_NUM_PARALLEL=4
        export OLLAMA_MAX_LOADED_MODELS=2
        
        # Start Ollama with restart capability
        start_ollama() {
          echo "ðŸš€ Starting Ollama server (attempt $1)..."
          nohup ollama serve > logs/server/ollama-$1.log 2>&1 &
          local pid=$!
          echo $pid > logs/ollama.pid
          
          # Wait for server to be ready
          for i in {1..60}; do
            if curl -sf http://0.0.0.0:11543/api/tags >/dev/null 2>&1; then
              echo "âœ… Ollama server started (PID: $pid)"
              return 0
            fi
            
            # Check if process is still running
            if ! kill -0 $pid 2>/dev/null; then
              echo "âŒ Ollama process died"
              cat logs/server/ollama-$1.log | tail -20
              return 1
            fi
            
            echo "â³ Waiting for Ollama... ($i/60)"
            sleep 2
          done
          
          echo "âŒ Ollama failed to respond"
          return 1
        }
        
        # Try starting with retries
        SUCCESS=false
        for attempt in {1..3}; do
          if start_ollama $attempt; then
            SUCCESS=true
            break
          fi
          echo "âš ï¸ Start attempt $attempt failed"
          
          # Try recovery if not the last attempt
          if [[ $attempt -lt 3 ]]; then
            ./recovery.sh || true
            sleep 5
          fi
        done
        
        if [[ "$SUCCESS" != "true" ]]; then
          echo "âŒ Failed to start Ollama after 3 attempts"
          exit 1
        fi
        
        # Verify server is accessible
        echo "ðŸ“‹ Testing Ollama API..."
        curl -v http://0.0.0.0:11543/api/tags 2>&1 | head -20
        
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Ollama server started successfully" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸŒ Setup Tunnels with Fallback
      id: setup-tunnels
      run: |
        echo "::group::Setting up Tunnels"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Setting up tunnels" >> logs/timeline.log
        
        TUNNEL_URLS=""
        TUNNEL_PROVIDER="${{ github.event.inputs.tunnel_provider }}"
        
        # Setup Cloudflare tunnel
        setup_cloudflare() {
          echo "ðŸŒ Starting Cloudflare tunnel..."
          nohup cloudflared tunnel --url http://0.0.0.0:11543 --no-autoupdate \
            --metrics 0.0.0.0:11544 > logs/tunnel/cloudflare.log 2>&1 &
          local pid=$!
          echo $pid > logs/cloudflare.pid
          
          # Wait for tunnel URL
          for i in {1..90}; do
            if [[ -f logs/tunnel/cloudflare.log ]]; then
              local url=$(grep -oE 'https://[a-zA-Z0-9-]*\.trycloudflare\.com' logs/tunnel/cloudflare.log | head -1)
              if [[ ! -z "$url" ]]; then
                # Verify tunnel works
                sleep 5
                if curl -sf "$url/api/tags" --max-time 10 >/dev/null 2>&1; then
                  echo "âœ… Cloudflare tunnel: $url"
                  echo "$url" > logs/cloudflare_url.txt
                  return 0
                fi
              fi
            fi
            
            if ! kill -0 $pid 2>/dev/null; then
              echo "âŒ Cloudflare tunnel process died"
              cat logs/tunnel/cloudflare.log | tail -20
              return 1
            fi
            
            echo "â³ Waiting for Cloudflare tunnel... ($i/90)"
            sleep 2
          done
          
          return 1
        }
        
        # Setup ngrok tunnel
        setup_ngrok() {
          if [[ -z "${{ env.NGROK_AUTH_TOKEN }}" ]]; then
            echo "â„¹ï¸ Ngrok not configured"
            return 1
          fi
          
          echo "ðŸŒ Starting ngrok tunnel..."
          nohup ngrok http 11543 --log=stdout > logs/tunnel/ngrok.log 2>&1 &
          local pid=$!
          echo $pid > logs/ngrok.pid
          
          # Wait for ngrok to start
          sleep 5
          
          # Get URL from ngrok API
          for i in {1..30}; do
            local url=$(curl -s http://localhost:4040/api/tunnels 2>/dev/null | \
                       jq -r '.tunnels[0].public_url' 2>/dev/null | \
                       sed 's/^http:/https:/')
            
            if [[ ! -z "$url" ]] && [[ "$url" != "null" ]]; then
              echo "âœ… Ngrok tunnel: $url"
              echo "$url" > logs/ngrok_url.txt
              return 0
            fi
            
            if ! kill -0 $pid 2>/dev/null; then
              echo "âŒ Ngrok process died"
              return 1
            fi
            
            echo "â³ Waiting for ngrok... ($i/30)"
            sleep 2
          done
          
          return 1
        }
        
        # Setup tunnels based on configuration
        CF_SUCCESS=false
        NGROK_SUCCESS=false
        
        if [[ "$TUNNEL_PROVIDER" == "cloudflare" ]] || [[ "$TUNNEL_PROVIDER" == "both" ]]; then
          setup_cloudflare && CF_SUCCESS=true
        fi
        
        if [[ "$TUNNEL_PROVIDER" == "ngrok" ]] || [[ "$TUNNEL_PROVIDER" == "both" ]]; then
          setup_ngrok && NGROK_SUCCESS=true
        fi
        
        # Determine primary URL
        PRIMARY_URL=""
        if [[ "$CF_SUCCESS" == "true" ]]; then
          PRIMARY_URL=$(cat logs/cloudflare_url.txt)
        elif [[ "$NGROK_SUCCESS" == "true" ]]; then
          PRIMARY_URL=$(cat logs/ngrok_url.txt)
        fi
        
        if [[ -z "$PRIMARY_URL" ]]; then
          echo "âŒ No tunnels established"
          exit 1
        fi
        
        echo "primary_url=$PRIMARY_URL" >> $GITHUB_OUTPUT
        echo "ðŸŒ Primary URL: $PRIMARY_URL"
        echo "$PRIMARY_URL" > logs/tunnel_url.txt
        
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Tunnels established" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸ“¥ Load Model with Smart Retry
      run: |
        echo "::group::Loading Model"
        MODEL="${{ github.event.inputs.model }}"
        if [[ "$MODEL" == "custom" ]]; then
          MODEL="${{ github.event.inputs.custom_model }}"
        fi
        
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Loading model: $MODEL" >> logs/timeline.log
        echo "ðŸ“¥ Loading model: $MODEL"
        
        export OLLAMA_HOST=0.0.0.0:11543
        
        # Check if model exists
        if ollama list 2>/dev/null | grep -q "$MODEL"; then
          echo "âœ… Model found in cache"
        else
          echo "ðŸ“¥ Downloading model..."
          
          # Monitor download progress
          monitor_download() {
            local log_file=$1
            local start_time=$(date +%s)
            
            while true; do
              if [[ -f "$log_file" ]]; then
                # Extract progress from log
                local progress=$(grep -oE '[0-9]+%' "$log_file" | tail -1)
                if [[ ! -z "$progress" ]]; then
                  echo "ðŸ“Š Download progress: $progress"
                fi
                
                # Check for completion
                if grep -q "success" "$log_file" 2>/dev/null; then
                  echo "âœ… Download completed"
                  return 0
                fi
                
                # Check for errors
                if grep -q "error\|failed" "$log_file" 2>/dev/null; then
                  echo "âŒ Download error detected"
                  return 1
                fi
              fi
              
              # Timeout check
              local current_time=$(date +%s)
              local elapsed=$((current_time - start_time))
              if [[ $elapsed -gt 1200 ]]; then
                echo "âŒ Download timeout (20 minutes)"
                return 1
              fi
              
              sleep 10
            done
          }
          
          # Try downloading with monitoring
          for attempt in {1..3}; do
            echo "ðŸ“¥ Download attempt $attempt/3..."
            
            # Start download in background
            timeout 1200 ollama pull "$MODEL" > logs/download-$attempt.log 2>&1 &
            DOWNLOAD_PID=$!
            
            # Monitor download
            if monitor_download "logs/download-$attempt.log"; then
              wait $DOWNLOAD_PID
              if [[ $? -eq 0 ]]; then
                echo "âœ… Model downloaded successfully"
                break
              fi
            else
              kill $DOWNLOAD_PID 2>/dev/null || true
            fi
            
            if [[ $attempt -lt 3 ]]; then
              echo "âš ï¸ Retrying download..."
              sleep 10
            else
              echo "âŒ Failed to download model after 3 attempts"
              exit 1
            fi
          done
        fi
        
        # Pre-load model
        echo "ðŸ”„ Pre-loading model..."
        timeout 60 ollama run "$MODEL" "test" >/dev/null 2>&1 || true
        
        # Verify model is loaded
        echo "ðŸ“‹ Loaded models:"
        ollama list
        
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Model loading completed" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸ“¡ Send Comprehensive Webhook
      if: always()
      continue-on-error: true
      run: |
        echo "::group::Sending Notifications"
        
        TUNNEL_URL="${{ steps.setup-tunnels.outputs.primary_url }}"
        MODEL="${{ github.event.inputs.model }}"
        if [[ "$MODEL" == "custom" ]]; then
          MODEL="${{ github.event.inputs.custom_model }}"
        fi
        
        # Prepare comprehensive payload
        PAYLOAD=$(jq -n \
          --arg event "ollama_ready" \
          --arg timestamp "$(date -u '+%Y-%m-%d %H:%M:%S UTC')" \
          --arg run_id "${{ github.run_id }}" \
          --arg runner_id "${{ needs.preflight-checks.outputs.runner_id }}" \
          --arg repo "${{ github.repository }}" \
          --arg model "$MODEL" \
          --arg url "$TUNNEL_URL" \
          --arg uptime "${{ github.event.inputs.keep_alive_minutes }}" \
          --argjson monitoring "${{ github.event.inputs.enable_monitoring }}" \
          '{
            event: $event,
            timestamp: $timestamp,
            workflow: {
              run_id: $run_id,
              runner_id: $runner_id,
              repository: $repo,
              url: ("https://github.com/" + $repo + "/actions/runs/" + $run_id)
            },
            server: {
              model: $model,
              url: $url,
              endpoints: {
                generate: ($url + "/api/generate"),
                chat: ($url + "/api/chat"),
                embeddings: ($url + "/api/embeddings"),
                models: ($url + "/api/tags")
              },
              uptime_minutes: $uptime,
              monitoring_enabled: $monitoring
            },
            system: {
              memory_free: "'$(free -h | awk "NR==2{print \$7}")'",
              cpu_load: "'$(uptime | awk -F"load average:" "{print \$2}")'",
              disk_free: "'$(df -h / | awk "NR==2{print \$4}")'"
            }
          }'
        )
        
        # Send to webhook
        if [[ ! -z "${{ env.WEBHOOK_URL }}" ]]; then
          echo "ðŸ“¡ Sending webhook..."
          for i in {1..3}; do
            if curl -X POST "${{ env.WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" \
              --max-time 30; then
              echo "âœ… Webhook sent"
              break
            fi
            echo "âš ï¸ Webhook attempt $i failed"
            sleep 5
          done
        fi
        
        # Send Telegram notification
        if [[ ! -z "${{ env.TELEGRAM_BOT_TOKEN }}" ]] && [[ ! -z "${{ env.TELEGRAM_CHAT_ID }}" ]]; then
          echo "ðŸ“± Sending Telegram notification..."
          MESSAGE="ðŸš€ *Ollama Server Ready*
        
        ðŸ”— URL: $TUNNEL_URL
        ðŸ¤– Model: $MODEL
        â±ï¸ Uptime: ${{ github.event.inputs.keep_alive_minutes }} minutes
        ðŸƒ Runner: ${{ needs.preflight-checks.outputs.runner_id }}
        
        Access your Ollama server now!"
          
          curl -X POST "https://api.telegram.org/bot${{ env.TELEGRAM_BOT_TOKEN }}/sendMessage" \
            -H "Content-Type: application/json" \
            -d "{
              \"chat_id\": \"${{ env.TELEGRAM_CHAT_ID }}\",
              \"text\": \"$MESSAGE\",
              \"parse_mode\": \"Markdown\"
            }" || echo "Telegram notification failed"
        fi
        
        echo "::endgroup::"
        
    - name: ðŸ“Š Advanced Monitoring System
      if: github.event.inputs.enable_monitoring == 'true'
      run: |
        echo "::group::Starting Monitoring"
        
        # Create comprehensive monitoring script
        cat > monitor_advanced.sh << 'EOF'
        #!/bin/bash
        
        LOG_DIR="logs/monitoring"
        HEALTH_LOG="$LOG_DIR/health.log"
        METRICS_LOG="$LOG_DIR/metrics.json"
        ALERT_LOG="$LOG_DIR/alerts.log"
        
        # Thresholds
        MEMORY_THRESHOLD=90
        CPU_THRESHOLD=80
        RESPONSE_TIME_THRESHOLD=5000
        
        check_health() {
          local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          local healthy=true
          local issues=""
          
          # Check Ollama process
          if ! pgrep -f ollama >/dev/null; then
            healthy=false
            issues="$issues ollama_dead"
            echo "âŒ [$timestamp] Ollama process not found" >> "$ALERT_LOG"
            
            # Attempt recovery
            if [[ -f recovery.sh ]]; then
              echo "ðŸ”§ Attempting automatic recovery..." >> "$ALERT_LOG"
              ./recovery.sh
            fi
          fi
          
          # Check API responsiveness
          local start_time=$(date +%s%N)
          if ! curl -sf http://0.0.0.0:11543/api/tags --max-time 5 >/dev/null 2>&1; then
            healthy=false
            issues="$issues api_unresponsive"
            echo "âŒ [$timestamp] API not responding" >> "$ALERT_LOG"
          else
            local end_time=$(date +%s%N)
            local response_time=$(( (end_time - start_time) / 1000000 ))
            
            if [[ $response_time -gt $RESPONSE_TIME_THRESHOLD ]]; then
              echo "âš ï¸ [$timestamp] Slow API response: ${response_time}ms" >> "$ALERT_LOG"
            fi
          fi
          
          # Check memory usage
          local mem_percent=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
          if [[ $mem_percent -gt $MEMORY_THRESHOLD ]]; then
            echo "âš ï¸ [$timestamp] High memory usage: ${mem_percent}%" >> "$ALERT_LOG"
          fi
          
          # Check CPU usage
          local cpu_percent=$(top -bn1 | grep "Cpu(s)" | awk '{print int($2)}')
          if [[ $cpu_percent -gt $CPU_THRESHOLD ]]; then
            echo "âš ï¸ [$timestamp] High CPU usage: ${cpu_percent}%" >> "$ALERT_LOG"
          fi
          
          # Log health status
          echo "[$timestamp] Health: $healthy, Issues: $issues" >> "$HEALTH_LOG"
          
          # Generate metrics JSON
          cat > "$METRICS_LOG" << METRICS
        {
          "timestamp": "$timestamp",
          "healthy": $healthy,
          "memory_percent": $mem_percent,
          "cpu_percent": $cpu_percent,
          "response_time_ms": ${response_time:-0},
          "issues": "$issues"
        }
        METRICS
        }
        
        # Main monitoring loop
        while true; do
          check_health
          sleep 30
        done
        EOF
        
        chmod +x monitor_advanced.sh
        nohup ./monitor_advanced.sh > logs/monitoring/monitor.log 2>&1 &
        echo $! > logs/monitor.pid
        
        echo "âœ… Advanced monitoring started"
        echo "::endgroup::"
        
    - name: â° Keep Server Alive with Auto-Recovery
      run: |
        echo "::group::Keep-Alive Loop"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Starting keep-alive" >> logs/timeline.log
        
        DURATION=$(( ${{ github.event.inputs.keep_alive_minutes }} * 60 ))
        START_TIME=$(date +%s)
        TUNNEL_URL=$(cat logs/tunnel_url.txt)
        
        echo "â° Keeping server alive for ${{ github.event.inputs.keep_alive_minutes }} minutes"
        echo "ðŸŒ Server URL: $TUNNEL_URL"
        
        # Health check counter
        HEALTH_FAILURES=0
        MAX_FAILURES=3
        
        while true; do
          CURRENT_TIME=$(date +%s)
          ELAPSED=$((CURRENT_TIME - START_TIME))
          REMAINING=$((DURATION - ELAPSED))
          
          if [[ $REMAINING -le 0 ]]; then
            echo "â° Keep-alive duration completed"
            break
          fi
          
          MINUTES_LEFT=$((REMAINING / 60))
          SECONDS_LEFT=$((REMAINING % 60))
          
          # Display status
          echo "â° Time remaining: ${MINUTES_LEFT}m ${SECONDS_LEFT}s ($(date '+%H:%M:%S'))"
          
          # Perform health check
          if ./health_check.sh; then
            HEALTH_FAILURES=0
          else
            HEALTH_FAILURES=$((HEALTH_FAILURES + 1))
            echo "âš ï¸ Health check failed ($HEALTH_FAILURES/$MAX_FAILURES)"
            
            if [[ $HEALTH_FAILURES -ge $MAX_FAILURES ]]; then
              echo "ðŸ”§ Triggering automatic recovery..."
              if ./recovery.sh; then
                echo "âœ… Recovery successful"
                HEALTH_FAILURES=0
              else
                echo "âŒ Recovery failed, attempting to continue..."
              fi
            fi
          fi
          
          # Status report every 5 minutes
          if [[ $((ELAPSED % 300)) -lt 30 ]] && [[ $((ELAPSED % 300)) -ge 0 ]]; then
            echo "ðŸ“Š 5-minute status report:"
            echo "  ðŸ’¾ Memory: $(free -h | grep Mem: | awk '{print $3"/"$2}')"
            echo "  ðŸ–¥ï¸  Load: $(uptime | awk -F'load average:' '{ print $2 }')"
            echo "  ðŸŒ Tunnel: $(curl -sf $TUNNEL_URL/api/tags >/dev/null 2>&1 && echo 'âœ… Active' || echo 'âŒ Unreachable')"
            echo "  ðŸ“Š Ollama: $(curl -sf http://0.0.0.0:11543/api/ps 2>/dev/null | jq -r '.models | length' 2>/dev/null || echo '0') models loaded"
          fi
          
          sleep 30
        done
        
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Keep-alive completed" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸ“Š Generate Final Report
      if: always()
      run: |
        echo "::group::Final Report"
        echo "==================== FINAL STATUS REPORT ===================="
        echo "ðŸ• Workflow completed at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        
        # Generate comprehensive report
        cat > logs/final_report.json << EOF
        {
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "workflow": {
            "run_id": "${{ github.run_id }}",
            "runner_id": "${{ needs.preflight-checks.outputs.runner_id }}",
            "status": "${{ job.status }}",
            "duration_seconds": $(($(date +%s) - $(date +%s -d "$(cat logs/timeline.log | head -1 | cut -d' ' -f1-2)"))),
            "repository": "${{ github.repository }}"
          },
          "server": {
            "ollama_running": $(pgrep -f ollama >/dev/null && echo true || echo false),
            "tunnel_active": $(curl -sf $(cat logs/tunnel_url.txt 2>/dev/null || echo "http://localhost")/api/tags >/dev/null 2>&1 && echo true || echo false),
            "model": "${{ github.event.inputs.model }}",
            "url": "$(cat logs/tunnel_url.txt 2>/dev/null || echo 'N/A')"
          },
          "resources": {
            "memory_used": "$(free -h | awk 'NR==2{print $3}')",
            "memory_total": "$(free -h | awk 'NR==2{print $2}')",
            "disk_used": "$(df -h / | awk 'NR==2{print $3}')",
            "cpu_load": "$(uptime | awk -F'load average:' '{print $2}')"
          },
          "cache": {
            "models_cached": $(find /home/runner/.ollama/models -type f 2>/dev/null | wc -l),
            "cache_size": "$(du -sh /home/runner/.ollama 2>/dev/null | cut -f1 || echo '0')"
          },
          "errors": [
            $(cat logs/error.log 2>/dev/null | jq -R -s 'split("\n") | map(select(. != ""))' || echo '[]')
          ],
          "recovery_attempts": $(cat logs/recovery.log 2>/dev/null | grep -c "Attempting recovery" || echo 0)
        }
        EOF
        
        # Display report
        cat logs/final_report.json | jq '.'
        
        # Show timeline
        echo ""
        echo "ðŸ“œ Workflow Timeline:"
        cat logs/timeline.log 2>/dev/null || echo "No timeline available"
        
        echo "============================================================"
        echo "::endgroup::"
        
    - name: ðŸ§¹ Cleanup and Save State
      if: always()
      run: |
        echo "::group::Cleanup"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Starting cleanup" >> logs/timeline.log
        
        # Stop monitoring
        if [[ -f logs/monitor.pid ]]; then
          kill $(cat logs/monitor.pid) 2>/dev/null || true
        fi
        
        # Gracefully stop services
        for service in ollama cloudflared ngrok; do
          if [[ -f logs/$service.pid ]]; then
            PID=$(cat logs/$service.pid)
            echo "ðŸ›‘ Stopping $service (PID: $PID)..."
            kill -TERM $PID 2>/dev/null || true
            
            # Wait for graceful shutdown
            for i in {1..10}; do
              if ! kill -0 $PID 2>/dev/null; then
                echo "âœ… $service stopped gracefully"
                break
              fi
              sleep 1
            done
            
            # Force kill if still running
            kill -9 $PID 2>/dev/null || true
          fi
        done
        
        # Save cache statistics
        echo "ðŸ“¦ Cache statistics:"
        du -sh /home/runner/.ollama/* 2>/dev/null || echo "No cache data"
        
        echo "âœ… Cleanup completed"
        echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') - Cleanup completed" >> logs/timeline.log
        echo "::endgroup::"
        
    - name: ðŸ’¾ Upload Comprehensive Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ollama-logs-${{ github.run_id }}
        path: |
          logs/
          *.log
          *.json
        retention-days: 7
        if-no-files-found: warn
        
  # Post-run analysis job
  post-analysis:
    needs: [preflight-checks, ollama-server]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
    - name: ðŸ“Š Analyze Run Performance
      run: |
        echo "::group::Performance Analysis"
        
        # Create analysis report
        cat > analysis.json << EOF
        {
          "run_id": "${{ github.run_id }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "status": "${{ needs.ollama-server.result }}",
          "metrics": {
            "preflight_status": "${{ needs.preflight-checks.result }}",
            "server_status": "${{ needs.ollama-server.result }}",
            "total_duration": "$(( $(date +%s) - ${{ github.run_id }} % 100000 )) seconds"
          },
          "recommendations": []
        }
        EOF
        
        # Add recommendations based on outcome
        if [[ "${{ needs.ollama-server.result }}" == "failure" ]]; then
          echo "âŒ Run failed - analyzing failure patterns..."
        elif [[ "${{ needs.ollama-server.result }}" == "success" ]]; then
          echo "âœ… Run successful - capturing best practices..."
        fi
        
        echo "::endgroup::"
        
    - name: ðŸ“¡ Send Final Notification
      if: env.WEBHOOK_URL != ''
      continue-on-error: true
      run: |
        curl -X POST "${{ env.WEBHOOK_URL }}" \
          -H "Content-Type: application/json" \
          -d '{
            "event": "workflow_completed",
            "run_id": "${{ github.run_id }}",
            "status": "${{ needs.ollama-server.result }}",
            "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
          }' || echo "Final webhook failed (non-critical)"
